---
title: Cloud Platform Operational Processes
last_reviewed_on: 2019-12-09
review_in: 3 months
---

# <%= current_page.data.title %>


This is a record of the operational processes that we will use to support our users and to maintain the cloud platform. 

### Hours of support

Our hours of providing support are 10am - 5pm. During this time we will work on support requests from teams and make sure someone is available to answer questions in Slack channel [`#ask-cloud-platform`](https://mojdt.slack.com/messages/C57UPMZLY/) and look at PR request notifications for the cloud-platform-environments repo on [`#cloud-platform-notify`](https://mojdt.slack.com/messages/CA5MDLM34/)

Outside of these hours we will respond to [high priority](#prioritising-incidents) incidents as per our [on call](#our-on-call-process) process.

### Working hours

A member of the support team will be available online from 9am and until 6pm. This team member can be working remotely. We are doing this so that we cover incident response for the time when the person on call is coming into the office or going home at the end of the day.

This support team member should be ready to respond to any high priority incidents.

### The support team

The key activities for the day are:

_On starting the day (9AM)_
At least one engineer to:

* Check the [`#low-priority-alarms`](https://mojdt.slack.com/messages/C8QR5FQRX/) and [`#high-priority-alarms`](https://mojdt.slack.com/messages/C8PF51AT0/) slack channels for any issues to investigate
* Check the board for any user requests that have been raised and not assigned
* Get a handover from the on call engineer about any issues out of hours
* Read through [`#ask-cloud-platform`](https://mojdt.slack.com/messages/C57UPMZLY/) slack channel

_During support hours (10AM - 5PM)_
At least one engineer to:

* Actively participate in [`#ask-cloud-platform`](https://mojdt.slack.com/messages/C57UPMZLY/) to field support requests, triage, prioritise and fix
* Monitor [`#high-priority-alarms`](https://mojdt.slack.com/messages/C8PF51AT0/) and [`#low-priority-alarms`](https://mojdt.slack.com/messages/C8QR5FQRX/) for incidents, triage, prioritise and fix
* Monitor [`#cloud-platform-notify`](https://mojdt.slack.com/messages/CA5MDLM34/) for cloud-platform-environments repo PR request notifications and cloud platform build notifications.
* Monitor user support requests being added to the board and triage them for priority

The whole support team to:

* Manage incident process for incidents in progress
* Work on user requests for larger work
* Work on support backlog stories

_Before ending the day (6PM)_
At least one engineer to:

* Handover information about any planned work or in progress high priority incidents to on call engineer

### `#ask-cloud-platform` slack channel

The [`#ask-cloud-platform`](https://mojdt.slack.com/messages/C57UPMZLY/) channel is our main entry point for support. We encourage people to ask questions and report problems in this channel and we'll do the best we can to help. We also welcome comments, opinions and any feedback regarding any of the services and the platform as a whole. This channel can also be used to communicate to other cloud platform users on topics you think that might be useful for other users.  

One of the Cloud Platform Team will be available to answer questions throughout the hours of support (10AM - 5PM).  

### What we communicate

The main purpose of [`#ask-cloud-platform`](https://mojdt.slack.com/messages/C57UPMZLY/) is to discuss the problems that people are having and help them to solve them.

### User support tickets

If someone is asking for help that will be quick to do (less than 15 mins) or is mainly advice then keep the interaction in channel and get it done.

If someone needs something that takes longer, is more challenging to complete or you find you've spent longer than 15 mins on it, then continue to talk in the channel but also ask the person asking for help to raise a ticket using the GitHub issue [link](https://github.com/ministryofjustice/cloud-platform/issues/new?template=cloud-platform-support-request.md&labels=support%20team).

The purpose of the ticket is to keep a record of the work we are doing and how it is progressing. It is *not* the primary communication channel with the person who raised the problem - this should remain slack where you can provide a richer and more human interaction, answering questions if necessary. The engineer working on the ticket should update the ticket for our record as work progresses.

In many cases it can be more helpful for the engineer on support to create the ticket rather than the person reporting the problem as you will be able to provide more relevant context.

Once they have created the ticket it will appear in the `Support New Issues` column of our [sprint board](https://app.zenhub.com/workspaces/cloud-platform-team-5ccb0b8a81f66118c983c189/board?repos=126507503,131595384,122635841,175829912). It can then be moved into the relevant columns as you work on it.

### `#cloud-platform-update` slack channel

[`#cloud-platform-update`](https://mojdt.slack.com/messages/CH6D099DF/) has been created to make broadcast communications, examples include:

* when there is planned work on a service (e.g. we are completing maintenance on Postgres RDS instance in prod)
* when there is an incident in progress (e.g there is a problem with Jenkins, no one can access it right now)

In these situations:

* try not to use notifiers like `@here` and `@channel` unless absolutely necessary
* perhaps use visual clues in your message to show it is an announcement
* commit to a time when you will update on the situation and keep that commitment

So for example:

>
**ANNOUNCEMENT:**
As agreed with the relevant teams, the cloud platform team will be upgrading Postgres from version 9.2 (out of support) to version 9.6 on CLA, Moving People Safely and Prison Visits Booking RDS instances today.

>
We will be doing this work between 10AM and 3PM, we will update at 1PM and 3PM to say how it is going.

### Our incident process

An incident starts when a member of the support team says that it has. It is usually triggered by an alert that indicates a problem. The team member that calls it will send a message saying that there is an incident in progress to [`#cloud-platform`](https://mojdt.slack.com/messages/C514ETYJX/) and if user impacting, [`#ask-cloud-platform`](https://mojdt.slack.com/messages/C57UPMZLY/) and [`#cloud-platform-update`](https://mojdt.slack.com/messages/CH6D099DF/)

1. Support team chooses an incident lead. This person will be the main investigator of the incident. They start to work on the problem, calling on other team members (from the whole team) to help as required.

2. The rest of the support team communicates the incident out to those who are impacted, including giving updates at regular intervals. People to include:
    * Users who are affected by the problem - via [`#ask-cloud-platform`](https://mojdt.slack.com/messages/C57UPMZLY/), [`#cloud-platform-update`](https://mojdt.slack.com/messages/CH6D099DF/) and the affected team's own slack channels.
    * Team members for awareness or as they might be able to help - via [`#cloud-platform`](https://mojdt.slack.com/messages/C514ETYJX/) and the `@cloud-platform-team` group
    * People in the team who manage communication with senior leadership in MoJ - Steve, Karen, Tony.

3. In a *high priority incident* (see below), the support team will gather every 1 hour to work out if additional people/skills are needed and update any external comms.

4. Once the incident is resolved, the support team will communicate that out and prepare for a postmortem.  

### Prioritising incidents

An incident is a system failure or degradation that has an impact on users of the cloud platform.

The size of that impact determines the priority of the incident. At the moment, we find it useful to categories incidents as high priority - we will begin work on any incident as soon as a member of the support team is available but high priority incidents require greater focus and communication.

### High priority

* Service outages of user facing services
* Slowdown or degradation of service on a user facing service
* Failure of a system that stops one or more teams from working
* Failure of a system that creates a major vulnerability in the cloud platform

### Postmortems

In the cloud platform team we follow the practice of better understanding system failures through [blameless postmortems](https://codeascraft.com/2012/05/22/blameless-postmortems/).

The point of a postmortem is to understand the various factors that led up to a system failure and to try to identify things that can be improved to try to stop a similar event occurring in future.

Our approach to postmortems is to:

* For high priority incidents to hold a group session as soon as possible after the incident is closed
* Develop a timeline of the activities that led to the incident and its resolution
* Walkthrough that timeline and use it to identify opportunities for improvements
* Emerge with a prioritised list of improvements to be made, with owners
* Write up and publish the postmortem, giving a record of the timeline and any actions that have been agreed

We currently publish our postmortem reports on [pagerduty](https://moj-digital-tools.pagerduty.com/postmortems/). We have agreement to make these public and are in the process of working out how to do that.

### Our on call process

Team members who are on call manage an on call rota in pagerduty. The on call rota consists of a primary engineer and a secondary engineer.

Team members that are new to the rota should ensure that they have a secondary who has enough knowledge and experience of the process to support them.

The hours of on call are 7AM–10AM and 5PM–10PM weekdays, 7AM-10PM weekends and bank holidays. 9AM - 10AM and 5PM - 6PM are additionally covered by a team member from support who is online during those periods.

On call team members will respond to high priority incidents out of hours and will work on those incidents for up to 1 hour. If the engineer is not able to resolve the issue within that timeframe they will:

* put the service into maintenance mode
* inform the affected team
* put together a plan to resolve the issue in hours

### Our documentation

All Cloud Platform documentation is openly available in Git repos stored on Github. The starting point for this documentation is the [Cloud Platform repo](https://github.com/ministryofjustice/cloud-platform).

For using Cloud Platform we have created the [Cloud Platform User Guide](https://user-guide.cloud-platform.service.justice.gov.uk). This guide is the "front door" to the Cloud Platform and contains concepts, tasks, walkthroughs and other reference to help teams use the Cloud Platform.

For our legacy systems based around the Template Deploy tooling, our documentation lives in [Confluence](https://dsdmoj.atlassian.net/wiki/spaces/PLAT/overview). This documentation includes architecture, runbooks and common issues.