---
title: Migrating from Live-0 to Live-1
last_reviewed_on: 2019-12-09
review_in: 3 months
---

# <%= current_page.data.title %>


## Overview

After some long consideration of possible options, the decision has been made to migrate from the `live-0` cluster to the new `live-1` cluster.

The reason behind this decision is based on the need to move to a dedicated AWS account, which will be much easier to support, and the need to move away from the Ireland (EU) region to the London (UK) region.

> **Currently, there is no fixed deadline by which services must migrate off Live-0.** This guide will be updated as and when this changes.

The purpose of this document is to aid development teams in migrating their existing applications from `live-0` to `live-1`.

The migration steps that need to be taken may differ for individual applications.

The following steps are for an application that is considered to be fairly normal and deployed through CircleCI.

Appending these steps are a few extra consideration points, that are not covered in the example, but may apply to your application.

## Accessing the Live-1 cluster

To access the `live-1` cluster, follow the steps in the [authentication][ug-authentication] section of this guide, and download your Kube config file.

Kubernetes provides a [brief guide][set-kubeconfig-env] on how to set up `kubectl` to use multiple config files simultaneously.

You should now be able to switch contexts between the `live-0` and `live-1` clusters.

## Generating a new environment

Start by following the guide to generate a new environment, this follows the same process as was followed for `live-0`, and you should use the same details as you did for your environment then.

[Environment generation guide.][ug-create-env]

Run a `kubectl get namespaces` to check your environment has been successfully created.

## Generating a new ECR repository

Once you've generated a new environment in the `live-1` cluster, you will need to generate a new ECR repository for your application to be pushed to.

The reason why the previous ECR repo can't be used is due to the new `live-1` cluster being hosted in a separate AWS account.

If you need reminding of the ECR creation process, please see the [user documentation][ug-create-ecr].

## Changing the CircleCI environment variables

Now that you have a new empty environment and ECR repository set-up, the next step is to point your existing CircleCI pipeline away from the `live-0` environment, to your new `live-1` environment.

This is done by replacing the CircleCI environment variables with the ones generated for your `live-1` environment and then rerunning the pipeline.

Our helper script expects environment variables to be named according to the list below where `<ENVIRONMENT>` should be replaced by some identifier of your choosing (eg.: `STAGING`, `PRODUCTION`).

Please refer to the instructions [here][ug-deploy-to-kubernetes].
The environment variables you will need to replace are as follows:

<div style="height:1px;font-size:1px;">&nbsp;</div>

| Variable   |            |
|----------|:-------------|
| `AWS_DEFAULT_REGION` |  The default region will now be `eu-west-2`. |
| `AWS_ACCESS_KEY_ID` | The access key can be found in the secret created by the ECR generation. This requires base64 decoding. |
| `AWS_SECRET_ACCESS_KEY` | The secret key can be found in the secret created by the ECR generation. This requires base64 decoding. |
| `ECR_ENDPOINT` | The ECR endpoint for all repos in `live-1` is `754256621582.dkr.ecr.eu-west-2.amazonaws.com` |
| `KUBE_ENV_<ENVIRONMENT>_NAME` | The cluster name is `live-1.cloud-platform.service.justice.gov.uk` |
| `KUBE_ENV_<ENVIRONMENT>_NAMESPACE` | This variable should be equal to the name of your namespace. |
| `KUBE_ENV_<ENVIRONMENT>_TOKEN` | The token can be found in your ServiceAccount's `Secret` (eg.: `circleci-token-abcdef`) and needs base64 decoding. |
| `KUBE_ENV_<ENVIRONMENT>_CACERT` | The cert is an attribute found in the ServiceAccount's `Secret` and does not need base64 decoding. |

<div style="height:1px;font-size:1px;">&nbsp;</div>

After triggering the CircleCI pipeline, your application should now deploy into your new environment.

## Other considerations

### PodSecurityPolicy
In the `live-1` cluster we are introducing a restrictive [`PodSecurityPolicy`][PodSecurityPolicy] as part of our effort to harden the cluster and provide a stable, secure and reliable service.

The major change this brings is that root containers are not allowed to run. What this means is that the containers that run on the platform need to run as a non-root user. The [solution][rails-app-dockerfile] is straightforward for images we build: by using the `USER` directive in the `Dockerfile` with a **numeric uid**.

Sometimes we use images built by third parties which may or may not have taken the steps to build them as non-root images. One such very common example is nginx from the dockerhub library. If you need to run an nginx container we recommend that you use the [`bitnami/nginx`][bitnami/nginx] image.

See [here][non-root-containers] for more information on non-root containers.

[ug-authentication]: tasks.html#authentication
[ug-create-ecr]: tasks.html#creating-an-ecr-repository
[ug-create-env]: tasks.html#create-an-environment
[ug-cleaning-up]: tasks.html#cleaning-up
[ug-deploy-to-kubernetes]: tasks.html#deploy-to-kubernetes
[set-kubeconfig-env]: https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/#set-the-kubeconfig-environment-variable
[PodSecurityPolicy]: https://kubernetes.io/docs/concepts/policy/pod-security-policy/
[rails-app-dockerfile]: https://github.com/ministryofjustice/cloud-platform-multi-container-demo-app/blob/9ad6caf101cc21117742e5ab2cbe5507efd54efd/rails-app/Dockerfile
[bitnami/nginx]: https://github.com/bitnami/bitnami-docker-nginx
[non-root-containers]: https://docs.bitnami.com/containers/how-to/work-with-non-root-containers